---
title: "" #ECL750<br>François Rousseu<br>Hiver 2021
author: ""
date: ""
output:
  html_document:
    depth: 5
    fig_height: 5
    fig_width: 6
    number_sections: no
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: yes
      smooth_scroll: no
---

<script>
    $(document).ready(function() {
      $items = $('div#TOC li');
      $items.each(function(idx) {
        num_ul = $(this).parentsUntil('#TOC').length;
        $(this).css({'text-indent': num_ul * 20, 'padding-left': 0});
      });

    });
</script>


<style>

pre.r {
    background-color: #EEEEEE;
    border-color: #DDDDDD;
    font-size: 14pt;
}

pre code {
  font-size: 11pt;
}

body {
  font-size: 14pt;
}

.main-container {
    max-width: 1700px !important;
}

#TOC {
  font-size: 12pt;
  border-color: white;
  max-width: 600px;
}

.list-group-item.active:focus{
    z-index: 2;
    color: darkgreen;
    background-color: #EEEEEE;
    border-color: red;
    font-weight: bolder;
    font-color: red;
}

.list-group-item.active:hover {
    z-index: 2;
    color: darkgreen;
    background-color: #EEEEEE;
    border-color: red;
    font-weight: bolder;
    font-color: red;
}

.list-group-item.active{
    z-index: 2;
    color: darkgreen;
    background-color: #EEEEEE;
    border-color: red;
    font-weight: bolder;
    font-color: red;
}

h1.title {
  margin-top: 50px;
  font-size: 42px;
  color: DarkGreen;
  font-weight: bold;
}

h1, h2, h3, h4, h5, h6 {
  padding-top: 800px;
  padding-bottom: 50px;
  color: DarkGreen;
  font-weight: bold;
}

h1 {
  font-size: 42px;
}

h2 {
  font-size: 36px;
}

h3 {
  font-size: 32px;
}

h4 {
  font-size: 28px;
}

h5 {
  font-size: 26px;
}

.pres { /* write {.pres} next to each section to apply css  */
   padding-top: 100px;
   margin-bottom: 700px;
}

</style>

```{r setup, include=FALSE}
library(scales)
knitr::opts_chunk$set(echo=TRUE, tidy=TRUE, error=TRUE, fig.align="center", fig.width=8, fig.height=6)
options(width=150)
```

<br>

# 1. Stats de base et modèles linéaires


## Distribution statistique

Décrit les probabilités d'apparition des valeurs d'une distribution donnée.


### Distribution normale

On parle aussi souvent d'une distribution Gaussienne.

<br>
  
$$ f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2} $$

<br>

où $\mu$ et $\sigma$ sont des paramètres, respectivement la moyenne et l'écart-type. 


#### Forme de la distribution normale

```{r}

x<-seq(-5,15,by=0.01)
mu<-5
sigma<-2
y<-(1/(sigma*sqrt(2*pi))*exp((-1/2)*((x-mu)/sigma)^2))
plot(x,y,type="l")

```

#### Simuler une distribution normale

On peut utiliser la fonction `rnorm` pour simuler des valeurs provenant d'une distribution normale.

```{r}
set.seed(123)
n<-1000
x<-rnorm(n,mu,sigma)
hist(x,breaks=50)
```

#### Interprétation

```{r}

v<-seq(-5,15,by=0.01)
hist(x,breaks=50,freq=FALSE,xlim=range(v))
curve(dnorm(x,mu,sigma),add=TRUE)
y<-dnorm(v,mu,sigma)
polygon(c(v[v>=6 & v<=8],8,6), c(y[v>=6 & v<=8],0,0),col=alpha("red",0.5),border=NA)

```

L'aire sous la courbe est de 1 et la proportion de cette surface en rouge représente la probabilité d'obtenir une valeur entre 6 et 8 avec une moyenne de $\mu = 5$ et un écart-type de $\sigma = 2$. On peut estimer cette probabilité avec la fonction `pnorm` intégrée à R. Ce type de fonction est intégré pour plusieurs distribution statistique (voir `?Distributions`).


##### Probabilité d'obtenir une valeur? 

```{r}

pnorm(5,mean=5,sd=2) # probabilité d'obtenir une valeur <= 5
pnorm(-2,mean=5,sd=2) # probabilité d'obtenir une valeur <= -2
pnorm(4,mean=5,sd=2) # probabilité d'obtenir une valeur <= 4

```

Probabilité d'obtenir une valeur entre 6 et 8

```{r}

pnorm(8,5,2)-pnorm(6,5,2)

```


#### Distribution d'une variable

<br>

$$ X \sim \mathcal{N}(\mu,\,\sigma^{2})\,$$

<br>

$X$ suit une distribution normale avec une moyenne $\mu$ et une variance $\sigma^{2}$
 

## Erreur-type

<br>

$$ se = \frac{sd}{\sqrt{n}} $$

<br>

ou

<br>

$$ \sigma_{\bar{x}} = \frac{\sigma_{x}}{\sqrt{n}} $$

<br>

```{r}
n<-100000
pop<-rnorm(n,100,20) # population fictive de n individus avec une moyenne de 100 et écart-type de 20
ech<-sample(pop,30) # échantillon aléatoire de 30 individus
mean(ech) # moyenne
sd(ech)/sqrt(30) # erreur-type
```


### Simulation

Ici, on refait cet échantillonnage `nreps` fois et on calcule l'écart-type des différentes moyennes obtenues.

```{r}

nreps<-1000
ech1000<-sapply(1:nreps,function(i){
  s<-sample(pop,30)	
  mean(s)
})
hist(ech1000)
```

#### Écart-type des valeurs simulées

```{r}

sd(ech1000)

```

Comparons ceci à l'erreur-type calculé à partir de notre seul échantillon:

```{r}

sd(ech)/sqrt(30) # erreur-type

```

##### Interprétation de l'erreur-type

L'écart-type de ces moyennes correspond à l'erreur-type estimée à partir d'un seul échantillon. En d'autres mots, l'erreur-type représente:


* l'écart-type si des moyennes obtenues si on refaisait plusieurs fois le même échantillonnage

* une mesure de précision dans l'estimation de  la moyenne

<br>

Le concept d'erreur-type s'applique aussi à d'autres paramètres estimés et pas seulement à la moyenne.  

<br>

L'erreur-type d'une statistique ou d'un paramètre est une estimation de l'écart-type de sa distribution d'échantillonnage.


## Intervalle de confiance

Reprenons notre population fictive `pop` qui a une moyenne de 100 et un écart-type de 20. On se rappelle qu'un intervalle de confiance pour une moyenne provenant d'un échantillon distribué normalement (ou presque) se calcule de la façon suivante:

<br>

$$\bar{x} ± t_{dl,\alpha/2}\sigma_{\bar{x}}$$

<br>

On peut calculer cet intervalle de confiance avec R:

```{r}

mean(ech)+qt(0.025,df=length(ech)-1,lower.tail=FALSE)*(sd(ech)/sqrt(length(ech)))*c(-1,1)

```

### Simulation

Maintenant, reprenons note population fictive et calculons à chaque fois cet intervalle de confiance. Ensuite, calculons quelle est la proportion des intervalles qui contiennent la véritable moyenne de 100.

```{r}

nreps<-1000
ech1000<-lapply(1:nreps,function(i){
  s<-sample(pop,30)	
  c(mean(s),mean(s)+qt(0.025,df=length(s)-1,lower.tail=FALSE)*(sd(s)/sqrt(length(s)))*c(-1,1))
})
ci<-as.data.frame(do.call("rbind",ech1000))
names(ci)<-c("mean","lowerCI","upperCI")

sum(100>=ci$lowerCI & 100<=ci$upperCI)/nreps

```

### Interprétation de l'intervalle de confiance

Un intervalle de confiance à 95% veut dire que 95% des intervalles de confiance qu'on obtiendrait si on refaisait le même échantillonnage contiendront la véritable moyenne de la population.

Plus généralement, on devrait parler d'un paramètre (moyenne, variance, pente, etc.) plutôt que d'une moyenne.

On entend souvent à tort que cela veut dire qu'il y a 95% de chances que le paramètre soit à l'intérieur des bornes. Or le paramètre est considéré comme étant fixe et la probabilité porte sur le fait que l'intervalle contienne la véritable valeur du paramètre ou pas.

Tout comme l'erreur-type, l'intervalle de confiance est une mesure de précision dans l'estimation d'un paramètre.

<!--

## Valeur de p

Un exemple avec le test de $t$ et une population fictive.
```{r}

set.seed(1)
n<-10000
pop1<-rnorm(n,20,3) # population fictive de n indoividus avec une moyenne de 20
pop2<-rnorm(n,21,3) # population fictive de n indoividus avec une moyenne de 21

ech1<-sample(pop1,10) # échantillon de 10 individus de chaque population
ech2<-sample(pop2,10)

test<-t.test(ech1,ech2)
test

```

### Interprétation de la Valeur de p

```{r}

plot(0,0,xlim=c(-4,4),ylim=c(0,0.5),type="n")
curve(dt(x,test$parameter),add=TRUE)
v<-seq(-5,15,by=0.01)
y<-dt(v,test$parameter)
polygon(c(v[v<=test$statistic],test$statistic,min(v)), c(y[v<=test$statistic],0,0),col=alpha("red",0.5),border=NA)
polygon(c(v[v>=abs(test$statistic)],max(v),abs(test$statistic)), c(y[v>=abs(test$statistic)],0,0),col=alpha("red",0.5),border=NA)

```

### Simulations

Reprenons le test de $t$ précédent, mais cette fois, prenons nos échantillons dans la même population (pop1) à chaque fois.

```{r}

nreps<-1000

tvalue<-sapply(1:nreps,function(i){
  ech1<-sample(pop1,5) 
  ech2<-sample(pop1,5)
  test<-t.test(ech1,ech2)
  test$statistic
})

hist(tvalue,breaks=50)

```

#### À compléter !!!!

-->

## Modèles linéaires simples

<br>

On a ici la formulation classique ou habituelle d'un modèle linéaire simple.

<br>

$$ y = \beta_{0} + \beta_{1}x_{1} + \beta_{2}x_{2} +  ...  + \beta_{n}x_{n} + \epsilon $$

$$ \epsilon \sim \mathcal{N}(0,\,\sigma^{2})\ $$


### Autre formulation

<br>

$$ \mu = \beta_{0} + \beta_{1}x_{1} + \beta_{2}x_{2} +  ...  + \beta_{n}x_{n}$$

$$ y \sim \mathcal{N}(\mu,\,\sigma^{2})\ $$

<br>

où 

<br>

$y$ = observations

$\mu$ = prédicteur linéaire

On a donc un modèle représentant le lien entre nos variables et on cherche à estimer les **paramètres** de ce modèles à l'aide de données.

### Suppositions de bases

Quelles sont les suppositions de bases d'un modèle linéaire tel que celui présenté?

* Normalité des résidus? 

* Homoscédasticité de la variance (la variance ne dépend pas de ou ne varie pas avec $x_{n}$)

* Linéarité des relations entre $x_{n}$ et $y$?

* Corrélation entre les $x_{n}$?

* Indépendence entre les observations?

<!-- peut-êwtre compléter avec une slide sur chaque et des solutions -->

### Simulations

* Une des meilleures façons de s'assurer qu'on comprend comment fonctionne un modèle

* Permet d'étudier le comportement d'un modèle avec des valeurs connues


### Simulons un modèle

```{r}
# nb d'observations
n<-200

# valeurs fictives des variables explicatives selon une distribution uniforme
x1<-runif(n,0,100)
x2<-runif(n,0,10)
x3<-runif(n,0,1)

# valeurs des paramètres beta
b0<-100
b1<-0.2
b2<-1
b3<--10

# prédicteur linéaire
mu<-b0+b1*x1+b2*x2+b3*x3

# observations à partir d'une distribution normale avec un écart-type de 5
y<-rnorm(n,mu,5)

# données
d<-data.frame(y,x1,x2,x3)

```

### Fonction `lm`

La fonction `lm` permet de faire des modèles linéaires simples, ce qui inclue les régressions simples, les ANOVAs, ANCOVAs, régression multiples, etc.

Remarquez l'utilisation de l'argument `data` où la fonction ira chercher les différents éléments spécifiés dans la formule.

```{r}

m<-lm(y~x1+x2+x3,data=d)

```

#### Coefficients

On peut appliquer plusieurs fonctions pour extraire les éléments d'un modèle, en particulier un modèle effectué avec la fonction `lm`.

```{r}
coef(m)
```

#### Sommaire

La fonction `summary` est la plus utile pour extraire l'information d'un modèle.

```{r}
summary(m)
```

##### Résidus

```{r}
summary(m)
```

<br>

La section `Residuals:` illustre la distribution des valeurs des résidus tout en illustrant les valeurs les plus extrêmes.

##### Coefficients

```{r}
summary(m)
```

<br>

Ici, la section `Coefficients:` donne chacun des paramètres associés au modèle. Pour chaque coefficient, un test est effectué et pour chaque test l'hypothèse nulle est que le coefficient est égal à zéro ($H_{0}: \beta_{p} = 0$). Remarquez que les coefficients suivent une distribution du t de Student. La façon de représenter la valeur de p représente bien le fait que cette valeur représente une probabilité d'obtenir un telle valeur de t donnée ou pire encore.

##### R2

```{r}
summary(m)
```

<br>

`Multiple R-squared` est le coefficient de détermination ($R^{2}$). Il représente la proportion de variance expliquée par les variables explicatives (i.e. par le modèle).

<br>

$$R^{2} = \frac{\textrm{Variance expliquée}}{\textrm{Variance totale}}$$

<br>

`Adjusted R-squared` est le coefficient de détermination ajusté pour le nombre de paramètres dans le modèle. Contrairement au $R^{2}$ standard, qui augmente toujours avec le nombre de paramètres et ce, même si les paramètres n'expliquent rien, le $R^{2}$ ajusté n'augmente pas avec le nombre de paramètres si ceux-ci ne sont d'aucune utilité pour expliquer le phénomène.

##### F-statistic

```{r}
summary(m)
```

<br>

Teste l'hypothèse nulle selon laquelle toute les pentes sont simultanément égales à zéro, i.e.:

<br>

$$ H_{0}: \beta_{1} = \beta_{2} = ... = \beta_{p} = 0 $$

<br>

Ce test  produit une valeur de $F$ qui représente un ratio de variances. Le rejet de cette hypothèse signifie qu'au moins une des pentes est différente de zéro. Intuitivement, cela peut être interprété comme signifiant que le modèle explique une portion significative de la variance. À noter que parfois, ce test peut être significatif, alors que les tests individuels sur chaque coefficient ne le sont pas ou vice versa. 

La function `anova` peut être utilisée pour effectuer ce test en l'appliquant sur un modèle ou sur plusieurs modèle pour comparer les modèles entre eux.

##### Variance résiduelle

```{r}
summary(m)
```

<br>

`Residual standard error` représente la variance résiduelle ou la variance non-expliquée par le modèle. Remarquez que cette valeur n'est pas très différente de la valeur de 5 qui a été utilisée pour simuler le modèle.


#### Vérification des suppositions de bases

On peut utiliser la fonction `plot` qui lorsqu'elle est appliquée sur un objet de classe `lm` produira des graphiques permettant de vérifier certaines suppositions de bases ou conditions d'application.

```{r}

par(mfrow=c(2,2))
plot(m)

```

##### Fonctions accessoires

On peut également créer facilement certains de ces graphiques avec d'autres fonctions.

```{r,fig.width=12,fig.height=4}

par(mfrow=c(1,3))
plot(resid(m),fitted(m))
hist(resid(m))
qqnorm(resid(m))
qqline(resid(m))

```

### Facteurs

```{r}

# simulations d'un facteur
d$fac<-factor(sample(c("A","B","C"),nrow(d),replace=TRUE))
d$y<-d$y+2*as.integer(d$fac)-1

# modèle modifié avec le facteur
m<-lm(y~x1+x2+x3+fac,data=d)
summary(m)

```

<!-- Les facteurs sont comparés par rapport au niveau de référence! -->


## Comprendre son modèle avec des graphiques

La fonction `predict` sert à calculer la valeur prédite par le modèle pour chaque observation. Par exemple, ceci permet de mettre en relation les valeurs observées et les valeurs prédites. La fonction `predict` dans ce cas calcule la valeur prédite par le modèle pour chaque observation dans la base de donnée.

```{r}

plot(d$y,predict(m))

```


### Soumettre de nouvelle valeurs à `predict`

Plus souvent, on veut illustrer l'effet de nos variables et pour cela, il faut soumettre des valeurs à la fonction `predict`. Cette fonction est très utile lorsque l'on veut un maximum de contrôle sur les valeurs à prédire.

```{r}

x<-seq(min(d$x1),max(d$x1),length.out=50)
nd<-data.frame(x1=x,x2=mean(d$x2),x3=mean(d$x3),fac="B") # on fixe les autres variables à leur valeur moyenne
p<-predict(m,newdata=nd)
plot(d$x1,d$y) # observations
lines(x,p) # valeurs prédites

```


### Package `visreg`

Le package [visreg](https://pbreheny.github.io/visreg/) permet d'illustrer facilement les prédictions d'un modèle (ou les effets marginaux des différentes variables explicatives). Il utilise en arrière-plan la fonction `predict`.

```{r,fig.width=8,fig.height=8}
library(visreg)
par(mfrow=c(2,2))
visreg(m)

```


#### Package `ggeffects`

Le package [ggeffects](https://strengejacke.github.io/ggeffects/index.html) permet également d'illustrer les prédictions d'un modèle, mais ce package se base sur l'utilisation du package [ggplot2](https://ggplot2.tidyverse.org/) pour construire les graphiques. Le principe demeure le même: en arrière-plan la fonction `predict` est utilisée. On peut également combiner les différents graphiques générés en utilisant le package [patchwork](https://patchwork.data-imaginist.com/index.html) et sa fonction `wrap_plots`.

```{r,fig.width=8,fig.height=8}
library(ggeffects)
library(patchwork)
g<-ggpredict(m)
p<-plot(g,add.data=TRUE,jitter=FALSE)
wrap_plots(p)

```


### Interactions

Dans vos mots, qu'est-ce qu'une interaction?

<!-- C'est lorsque l'effet d'une variable dépend des valeurs d'une autre variable (ou de plusieurs) -->


#### Un exemple

```{r}

# modèle modifié avec le facteur
m<-lm(y~x1+x2+x3+x1*fac,data=d)
summary(m)

```


#### Illustration graphique

```{r}

visreg(m,"x1",by="fac",overlay=TRUE)

```

<br>

On a une interaction significative, mais est-elle importante d'un point de vue biologique? Peut-être pas... Toujours distinguer entre la **signification statistique** et la **signification biologique**.

Une valeur de p significative c'est bien beau, mais ce qui importe vraiment c'est **la taille de l'effet**.


##### Interactions avec `ggeffects`

```{r}

g<-ggpredict(m,terms=c("x1","fac"))
plot(g,add.data=TRUE,jitter=FALSE)

```


#### Interprétion

* Beaucoup plus facile avec un graphique qu'en regardant une table de coefficients.

* En présence d'une interaction (significative), les effets simples sont plus difficilement interprétables et ne peuvent être interprétés sans faire référence à l'interaction (à moins d'ajustements particuliers voir [Schielzeth 2010](https://doi.org/10.1111/j.2041-210X.2010.00012.x)).

* Si pour deux variables impliquées dans une interaction les effets simples ne sont pas significatifs, mais que leur interaction l'est, il faut considérer que ces deux variables ont un effet même si les coefficients associés aux effets simples ne sont pas significatifs.


## Types d'erreurs

<br>

* Erreur de type I: 

<br>

* Erreur de type II: 

<!-- le fait de rejeter l'hypothèse nulle, alors qu'elle est vraie. -->

<!-- le fait de ne pas rejeter l'hypothèse nulle, alors qu'elle est fausse -->


### Simulations 

Simulons un modèle dans lequel les variables n'ont aucun effet. 

Que se passera-t-il si on répète plusieurs fois ce scénario?

À quoi ressembleront nos valeurs de p?

Créons d'abord une fonction `sim_model` pour générer un modèle linéaire fictif. 

```{r}

sim_model<-function(b0,b1,b2,b3){
  n<-200
  x1<-runif(n,0,100)
  x2<-runif(n,0,10)
  x3<-runif(n,0,1)
  mu<-b0+b1*x1+b2*x2+b3*x3
  y<-rnorm(n,mu,5)
  d<-data.frame(y,x1,x2,x3)
  m<-lm(y~x1+x2+x3,data=d)
  m
}
```


#### Simulons

Ensuite, simulons `nsims` modèles fictifs et emmagasinons ces modèles dans une liste nommée `list_models`.

```{r}
nsims<-500

list_models<-lapply(1:nsims,function(i){
  sim_model(b0=100,b1=0,b2=0,b3=0)  
})
```

<br>

Si on illustre les valeurs de p obtenues pour chacun des coefficients associés aux variables $x_{n}$ à l'aide d'un histogramme, à quoi ressemblera cet histogramme?


#### Valeurs de p obtenus


```{r}

p<-lapply(list_models,function(i){
  summary(i)$coef[2:4,4]
})

hist(unlist(p),breaks=seq(0,1,by=0.05),xlab="Valeurs de p")

```


##### Conclusions

* Dans une certaine proportion des cas ( ~ 5% ), on conclut à un effet, alors qu'il n'y en a pas pas! C'est le fameux seuil $\alpha$ de 0.05.

* Sous l'hypothèse nulle, les valeurs de p sont distribuées uniformément entre 0 et 1.



## Extensions

<br>

Quelles sont les suppositions de bases qui sont susceptibles de ne pas être rencontrées?

* Résidus non-distribués normalement

* Non-égalité des variances

* Non-indépendence des observations

* Relation non-linéaire 

* Etc.

<br>

À voir au prochain cours!


# Liens utiles

[A protocol for data exploration to avoid common statistical problems](https://doi.org/10.1111/j.2041-210X.2009.00001.x)

[A protocol for conducting and presenting results of regression-type analyses](https://doi.org/10.1111/2041-210X.12577)

[Applied statistics in ecology: common pitfalls and simple solutions](https://doi.org/10.1890/ES13-00160.1)

[Simple means to improve the interpretability of regression coefficients](https://doi.org/10.1111/j.2041-210X.2010.00012.x)

<!-- to do, modèle linéaire, simul t.test, simule CI, check début, each verif assump plot, à compléter, revise all, list Zuur papers, read Marc again -->

<!--

# 2. Modèles linéaires généraux, généralisés et extensions


# 3. Vraisemblance, sélection de modèles et régularisation


# 4. Introduction aux statistiques bayésiennes

-->


